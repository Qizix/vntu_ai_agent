import asyncio
import json
import requests
import streamlit as st
import os

# –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –∑–æ–≤–Ω—ñ—à–Ω—å–æ–≥–æ FAISS-—ñ–Ω–¥–µ–∫—Å—É —Ç–∞ –º–æ–¥–µ–ª—ñ SentenceTransformer
from sentence_transformers import SentenceTransformer
import faiss


OLLAMA_API_URL = "http://127.0.0.1:11434/api/generate"  # –ï–Ω–¥–ø–æ—ñ–Ω—Ç Ollama
FAISS_INDEX_PATH = "Data/processed/big/vector_index.faiss"
MODEL_PATH = "Data/processed/big/sentence_transformer_model"

os.environ["STREAMLIT_WATCH_FILE"] = "false"


# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ —Ç–∞ FAISS —ñ–Ω–¥–µ–∫—Å—É
@st.cache_resource
def load_resources():
    print("Loading model and index...")
    model = SentenceTransformer(MODEL_PATH)
    index = faiss.read_index(FAISS_INDEX_PATH)
    with open("Data/processed/big_processed_results.json", "r", encoding="utf-8") as f:
        texts = json.load(f)
    return model, index, texts


model, index, texts = load_resources()


# *** –î–æ–ø–æ–º—ñ–∂–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è: –ó–∞–ø–∏—Ç –¥–æ FAISS ***
def find_similar_texts(query, k=5):
    query_embedding = model.encode([query])
    distances, indices = index.search(query_embedding, k)
    # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –Ω–∞–π–±–ª–∏–∂—á—ñ —Å—É—Å—ñ–¥–∏
    results = [{"text": texts[idx], "distance": float(distance)} for idx, distance in zip(indices[0], distances[0])]
    return results


# *** –î–æ–ø–æ–º—ñ–∂–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è: –°—Ç—Ä—ñ–º—ñ–Ω–≥ –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π –≤—ñ–¥ Ollama ***
async def call_ollama(prompt):
    data = {"model": "phi4", "prompt": prompt}
    with requests.post(OLLAMA_API_URL, json=data, stream=True) as response:
        if response.status_code == 200:
            for chunk in response.iter_lines(decode_unicode=True):
                if chunk:
                    try:
                        chunk_data = json.loads(chunk)
                        if "response" in chunk_data:
                            yield chunk_data["response"]
                    except json.JSONDecodeError:
                        continue
        else:
            yield f"Error: {response.status_code} {response.text}"


# *** –í–µ–±-—ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å –Ω–∞ –æ—Å–Ω–æ–≤—ñ Streamlit ***
st.title("üéì –î—Ä—É–∂–Ω—ñ–π AI-–ø–æ–º—ñ—á–Ω–∏–∫ –í–ù–¢–£")

# –î–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä—ñ—ó —á–∞—Ç—É
if "messages" not in st.session_state:
    st.session_state.messages = []


# –û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –ø–æ—à—É–∫—É
async def handle_user_input(user_input):
    # –î–æ–¥–∞—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
    st.session_state.messages.append({"role": "user", "content": user_input})

    # –®—É–∫–∞—î–º–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ —É FAISS
    similar_texts = find_similar_texts(user_input)

    # –Ø–∫—â–æ —Ç–µ–∫—Å—Ç—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ
    if not similar_texts:
        st.session_state.messages.append({"role": "agent",
                                          "content": "–ù–∞ –∂–∞–ª—å, —è –ø–æ–∫–∏ —â–æ –Ω–µ –º–æ–∂—É –∑–Ω–∞–π—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Ü–µ. –ê–ª–µ –º–æ–∂—É —Å–ø—Ä–æ–±—É–≤–∞—Ç–∏ –¥–æ–ø–æ–º–æ–≥—Ç–∏ —ñ–Ω—à–∏–º —Å–ø–æ—Å–æ–±–æ–º!"})
        return

    # –§–æ—Ä–º—É—î–º–æ –æ–±–º–µ–∂–µ–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è Ollama
    MAX_LENGTH = 5000  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Å–∏–º–≤–æ–ª—ñ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
    context = "\n\n".join(
        [
            f"Context {i + 1}: {result['text']['processed_text'][:500]}"
            for i, result in enumerate(similar_texts)
        ][:5]  # –ë–µ—Ä–µ–º–æ –º–∞–∫—Å–∏–º—É–º 5 —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω
    )[:MAX_LENGTH]  # –û–±—Ä—ñ–∑–∞—î–º–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç, —è–∫—â–æ –≤—ñ–Ω –ø–µ—Ä–µ–≤–∏—â—É—î –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–æ–ø—É—Å—Ç–∏–º—É –¥–æ–≤–∂–∏–Ω—É

    friendly_prompt = (
        "–¢–∏ ‚Äî –¥—Ä—É–∂–Ω—ñ–π —ñ –¥–æ–±—Ä–æ–∑–∏—á–ª–∏–≤–∏–π –≤—ñ—Ä—Ç—É–∞–ª—å–Ω–∏–π –ø–æ–º—ñ—á–Ω–∏–∫ –í—ñ–Ω–Ω–∏—Ü—å–∫–æ–≥–æ –Ω–∞—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Ö–Ω—ñ—á–Ω–æ–≥–æ —É–Ω—ñ–≤–µ—Ä—Å–∏—Ç–µ—Ç—É (–í–ù–¢–£). "
        "–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π –∫–æ—Ä–æ—Ç–∫–æ —ñ –ø–æ —Å—É—Ç—ñ, –∑–æ—Å–µ—Ä–µ–¥–∂—É—é—á–∏—Å—å –ª–∏—à–µ –Ω–∞ –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–∏—Ö –¥–∞–Ω–∏—Ö. "
        "–ù–µ –≤–∏–≥–∞–¥—É–π –¥–µ—Ç–∞–ª–µ–π, —è–∫—â–æ –Ω–µ –º–∞—î—à —Ç–æ—á–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó. "
        "–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –Ω–∞—Å—Ç—É–ø–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ:\n\n"
        f"{context}\n\n–ó–∞–ø–∏—Ç: {user_input}\n–í—ñ–¥–ø–æ–≤—ñ–¥—å:"
    )

    # –Ü–Ω—ñ—Ü—ñ—é—î–º–æ —Å—Ç—Ä—ñ–º—ñ–Ω–≥ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
    response_placeholder = st.empty()  # –í—ñ–∫–Ω–æ –¥–ª—è –≤–∏–≤–µ–¥–µ–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
    agent_response = []

    # –ó–±—ñ—Ä —á–∞—Å—Ç–∫–æ–≤–æ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
    MAX_AGENT_RESPONSE_LENGTH = 5000  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –¥–æ–≤–∂–∏–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ —É —Å–∏–º–≤–æ–ª–∞—Ö
    async for partial_response in call_ollama(friendly_prompt):
        if len("".join(agent_response)) < MAX_AGENT_RESPONSE_LENGTH:
            agent_response.append(partial_response)
            response_placeholder.write("".join(agent_response))  # –ü–æ—Å—Ç—É–ø–æ–≤–µ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è —Ç–µ–∫—Å—Ç—É

    # –ó–∞–ø–∏—Å—É—î–º–æ –æ—Å—Ç–∞—Ç–æ—á–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å –≤ —ñ—Å—Ç–æ—Ä—ñ—é
    st.session_state.messages.append({"role": "agent", "content": "".join(agent_response)})


# –†–µ–Ω–¥–µ—Ä–∏–Ω–≥ —á–∞—Ç—É
def render_chat():
    for message in st.session_state.messages:
        st.markdown(f"<div style='text-align: right; background: #0078d7; color: white; padding: 10px; "
                    f"border-radius: 5px; margin: 10px 5px;'>{message['content']}</div>", unsafe_allow_html=True)



# –í–∏–≤–µ–¥–µ–Ω–Ω—è —á–∞—Ç—É
render_chat()

# –ü–æ–ª–µ –¥–ª—è –≤–≤–µ–¥–µ–Ω–Ω—è –∑–∞–ø–∏—Ç—É
user_input = st.text_input("–í–≤–µ–¥—ñ—Ç—å —Å–≤—ñ–π –∑–∞–ø–∏—Ç –¥–æ –ø–æ–º—ñ—á–Ω–∏–∫–∞ –í–ù–¢–£:")
if user_input:
    # –í–∏–∫–æ–Ω–∞–Ω–Ω—è –æ–±—Ä–æ–±–∫–∏ asynchronously
    asyncio.run(handle_user_input(user_input))

# –ü–µ—Ä–µ—Ä–µ–Ω–¥–µ—Ä —á–∞—Ç—É
render_chat()

