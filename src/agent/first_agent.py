import faiss
import numpy as np
import json
from sentence_transformers import SentenceTransformer
from fastapi import FastAPI
from pydantic import BaseModel
import requests  # Для запитів до Ollama API

# Ініціалізація FastAPI
app = FastAPI()

# Завантаження необхідних компонентів
print("Loading model, FAISS index, and texts...")

# Завантаження SentenceTransformer моделі
model = SentenceTransformer("Data/processed/wiki/sentence_transformer_model")  # Ваша модель векторайзера
print("Model loaded.")

# Завантаження FAISS-індексу
index = faiss.read_index("Data/processed/wiki/vector_index.faiss")
print("FAISS index loaded.")

# Завантаження даних текстів
with open("Data/processed/wiki_processed_results.json", "r", encoding="utf-8") as file:
    texts = json.load(file)
print("Texts loaded.")

# Налаштування API Ollama
OLLAMA_API_URL = "http://127.0.0.1:11434/api/generate"  # Локальний ендпоінт Ollama API


# Допоміжна функція: Знаходження схожих текстів
def find_similar_texts(query: str, k: int = 5):
    # Генерація ембеддингу для запиту
    query_embedding = model.encode([query])

    # Пошук найближчих сусідів у FAISS
    distances, indices = index.search(query_embedding, k)

    # Формування результатів
    results = [{"text": texts[idx], "distance": float(distance)} for idx, distance in zip(indices[0], distances[0])]
    return results


# Допоміжна функція: Запит до Ollama
def query_ollama(model_name: str, prompt: str):
    # Структура даних для запиту
    data = {
        "model": model_name,  # Назва моделі в Ollama
        "prompt": prompt,
    }

    # Робимо запит до Ollama API
    with requests.post(OLLAMA_API_URL, json=data, stream=True) as response:
        if response.status_code == 200:
            try:
                # Ініціалізуємо змінну для збору частин відповіді
                full_response = ""

                # Перебираємо частини стрімінгової відповіді
                for chunk in response.iter_lines(decode_unicode=True):
                    if chunk:  # Перевіряємо, щоб частина не була порожньою
                        try:
                            # Декодуємо частину JSON
                            chunk_data = json.loads(chunk)

                            # Перевіряємо, чи є ключ "response"
                            if "response" in chunk_data:
                                full_response += chunk_data["response"]
                        except json.JSONDecodeError:
                            # Ігноруємо некоректні фрагменти
                            continue

                # Якщо після збору відповіді вона порожня, повертаємо помилку
                if not full_response.strip():
                    return "No response generated by the model. Check the prompt or context for relevancy."

                return full_response.strip()  # Повертаємо зібрану відповідь
            except Exception as e:
                # Якщо сталася будь-яка інша помилка
                raise Exception(f"Failed to process streaming response from Ollama API: {e}")
        else:
            # Якщо статус відповіді не 200, повідомляємо про помилку
            raise Exception(f"Ollama API error: {response.status_code}, {response.text}")



# FastAPI маршрут: Запит до агента
class QueryRequest(BaseModel):
    query: str
    num_results: int = 5  # Кількість результатів FAISS


@app.post("/agent")
def agent_endpoint(request: QueryRequest):
    try:
        # Крок 1: Пошук схожих текстів у FAISS
        similar_texts = find_similar_texts(request.query, request.num_results)

        # Якщо не знайдено жодного тексту
        if not similar_texts:
            return {
                "query": request.query,
                "response": "Немає релевантного контексту до вашого запиту. Спробуйте уточнити або змінити запит.",
                "context": []
            }

        # Крок 2: Формуємо контекст
        context = "\n\n".join([
            f"Context {i + 1}: {result['text']['processed_text'][:500]}"
            # Обрізаємо, щоб уникнути надлишкового контексту
            for i, result in enumerate(similar_texts)
        ])

        # Крок 3: Формування промпту для Ollama
        prompt = f"Використовуй контекст щоб відповісти на запит:\n\n{context}\n\nЗапит: {request.query}\nВідповідь:"

        # Крок 4: Виклик Ollama API
        response = query_ollama("phi4", prompt)

        # Формуємо фінальний результат
        return {
            "query": request.query,
            "response": response.strip(),  # Прибираємо зайві пробіли
            "context": similar_texts
        }

    except Exception as e:  # Усі інші помилки
        return {
            "error": True,
            "message": str(e),
            "query": request.query,
            "response": "Сталася помилка під час обробки вашого запиту. Повідомте адміністратора."
        }